{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PrivBayes import greedy_bayes, construct_noisy_conditional_distributions\n",
    "from utils import preprocessing, encoding, display_bayesian_network, get_school_list\n",
    "from model_alpha import model_alpha_synthetic_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_df = pd.read_excel('data/2021.xlsx', sheet_name='Resultaten')\n",
    "schools_df = pd.read_excel('data/2021.xlsx', sheet_name='Klassen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = get_school_list(schools_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basisschool advies</th>\n",
       "      <th>Voorkeur 1</th>\n",
       "      <th>Voorkeur 2</th>\n",
       "      <th>Voorkeur 3</th>\n",
       "      <th>Voorkeur 4</th>\n",
       "      <th>Voorkeur 5</th>\n",
       "      <th>Voorkeur 6</th>\n",
       "      <th>Voorkeur 7</th>\n",
       "      <th>Voorkeur 8</th>\n",
       "      <th>Voorkeur 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Voorkeur 13</th>\n",
       "      <th>Voorkeur 14</th>\n",
       "      <th>Voorkeur 15</th>\n",
       "      <th>Voorkeur 16</th>\n",
       "      <th>Voorkeur 17</th>\n",
       "      <th>Voorkeur 18</th>\n",
       "      <th>Voorkeur 19</th>\n",
       "      <th>Voorkeur 20</th>\n",
       "      <th>Voorkeur 21</th>\n",
       "      <th>Voorkeur 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havo</td>\n",
       "      <td>135</td>\n",
       "      <td>37</td>\n",
       "      <td>138</td>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>109</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>havo/vwo</td>\n",
       "      <td>135</td>\n",
       "      <td>64</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>102</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>havo/vwo</td>\n",
       "      <td>138</td>\n",
       "      <td>135</td>\n",
       "      <td>102</td>\n",
       "      <td>137</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>99</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>109</td>\n",
       "      <td>141</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>havo/vwo</td>\n",
       "      <td>135</td>\n",
       "      <td>95</td>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>134</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>99</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>havo</td>\n",
       "      <td>135</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>109</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Basisschool advies  Voorkeur 1  Voorkeur 2  Voorkeur 3  Voorkeur 4  \\\n",
       "0               havo         135          37         138         104   \n",
       "1           havo/vwo         135          64         137          40   \n",
       "2           havo/vwo         138         135         102         137   \n",
       "3           havo/vwo         135          95         137         138   \n",
       "4               havo         135          40          42         109   \n",
       "\n",
       "   Voorkeur 5  Voorkeur 6  Voorkeur 7  Voorkeur 8  Voorkeur 9  ...  \\\n",
       "0          52         109         102          81         130  ...   \n",
       "1           5          42          99         102         109  ...   \n",
       "2          37          68          99          81          20  ...   \n",
       "3         134          32         104          99          35  ...   \n",
       "4         137         132          30          37         127  ...   \n",
       "\n",
       "   Voorkeur 13  Voorkeur 14  Voorkeur 15  Voorkeur 16  Voorkeur 17  \\\n",
       "0          181          181          181          181          181   \n",
       "1          181          181          181          181          181   \n",
       "2          148          109          141           40          181   \n",
       "3           40          181          181          181          181   \n",
       "4          181          181          181          181          181   \n",
       "\n",
       "   Voorkeur 18  Voorkeur 19  Voorkeur 20  Voorkeur 21  Voorkeur 22  \n",
       "0          181          181          181          181          181  \n",
       "1          181          181          181          181          181  \n",
       "2          181          181          181          181          181  \n",
       "3          181          181          181          181          181  \n",
       "4          181          181          181          181          181  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices_df = preprocessing(choices_df)\n",
    "choices_df = encoding(choices_df, schools)\n",
    "choices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Basisschool advies', 'Voorkeur 1', 'Voorkeur 2', 'Voorkeur 3',\n",
       "       'Voorkeur 4', 'Voorkeur 5', 'Voorkeur 6', 'Voorkeur 7', 'Voorkeur 8',\n",
       "       'Voorkeur 9', 'Voorkeur 10', 'Voorkeur 11', 'Voorkeur 12',\n",
       "       'Voorkeur 13', 'Voorkeur 14', 'Voorkeur 15', 'Voorkeur 16',\n",
       "       'Voorkeur 17', 'Voorkeur 18', 'Voorkeur 19', 'Voorkeur 20',\n",
       "       'Voorkeur 21', 'Voorkeur 22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data using PrivBayes (correlated attribute mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_types = choices_df['Basisschool advies'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT Voorkeur 7\n",
      "Adding attribute Voorkeur 5\n",
      "Adding attribute Voorkeur 8\n",
      "Adding attribute Voorkeur 6\n",
      "Adding attribute Voorkeur 4\n",
      "Adding attribute Voorkeur 3\n",
      "Adding attribute Voorkeur 9\n",
      "Adding attribute Voorkeur 2\n",
      "Adding attribute Voorkeur 10\n",
      "Adding attribute Voorkeur 1\n",
      "========================== BN constructed ==========================\n",
      "Constructed Bayesian network:\n",
      "    Voorkeur 5  has parents ['Voorkeur 7'].\n",
      "    Voorkeur 8  has parents ['Voorkeur 5', 'Voorkeur 7'].\n",
      "    Voorkeur 6  has parents ['Voorkeur 5', 'Voorkeur 8', 'Voorkeur 7'].\n",
      "    Voorkeur 4  has parents ['Voorkeur 5', 'Voorkeur 8', 'Voorkeur 6', 'Voorkeur 7'].\n",
      "    Voorkeur 3  has parents ['Voorkeur 5', 'Voorkeur 8', 'Voorkeur 6', 'Voorkeur 4', 'Voorkeur 7'].\n",
      "    Voorkeur 9  has parents ['Voorkeur 5', 'Voorkeur 6', 'Voorkeur 4', 'Voorkeur 3', 'Voorkeur 7'].\n",
      "    Voorkeur 2  has parents ['Voorkeur 5', 'Voorkeur 6', 'Voorkeur 4', 'Voorkeur 9', 'Voorkeur 7'].\n",
      "    Voorkeur 10 has parents ['Voorkeur 8', 'Voorkeur 3', 'Voorkeur 9', 'Voorkeur 2', 'Voorkeur 5'].\n",
      "    Voorkeur 1  has parents ['Voorkeur 4', 'Voorkeur 3', 'Voorkeur 9', 'Voorkeur 10', 'Voorkeur 6'].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-98853e67a546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mconditional_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_noisy_conditional_distributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst10_vwo_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sampling_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\Downloads\\thesis\\PrivBayes.py\u001b[0m in \u001b[0;36mconstruct_noisy_conditional_distributions\u001b[1;34m(bayesian_network, encoded_dataset, epsilon)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mkplus1_attributes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[0mnoisy_dist_of_kplus1_attributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_noisy_distribution_of_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkplus1_attributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# generate noisy distribution of root attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\Downloads\\thesis\\PrivBayes.py\u001b[0m in \u001b[0;36mget_noisy_distribution_of_attributes\u001b[1;34m(attributes, encoded_dataset, epsilon)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mdata_frame_append\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[0mfull_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_frame_append\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   8963\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8964\u001b[0m         return (\n\u001b[1;32m-> 8965\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   8966\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8967\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\taanh\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             new_data = concatenate_managers(\n\u001b[0m\u001b[0;32m    533\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\taanh\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;31m#  we can use np.concatenate, which is more performant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m#  than concat_compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[1;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from pandas import DataFrame\n",
    "\n",
    "vwo = choices_df[choices_df['Basisschool advies'] == 'vwo']\n",
    "first10_vwo_df = vwo[['Voorkeur 1', 'Voorkeur 2', 'Voorkeur 3', 'Voorkeur 4', 'Voorkeur 5']]\n",
    "\n",
    "bn = greedy_bayes(first10_vwo_df, k=0, epsilon=0.1 / 2, seed=0)\n",
    "display_bayesian_network(bn)\n",
    "\n",
    "epsilon=0.1\n",
    "conditional_probabilities = construct_noisy_conditional_distributions(bn, first10_vwo_df, epsilon/2)\n",
    "\n",
    "def get_sampling_order(bn):\n",
    "    order = [bn[0][1][0]]\n",
    "    for child, _ in bn:\n",
    "        order.append(child)\n",
    "    return order\n",
    "\n",
    "def bayesian_network_synthetic_generator(n, bn, conditional_probabilities):\n",
    "    bn_root_attr = bn[0][1][0]\n",
    "    root_attr_dist = conditional_probabilities[bn_root_attr]\n",
    "    synthetic_df = DataFrame(columns=get_sampling_order(bn))\n",
    "    synthetic_df[bn_root_attr] = random.choice(len(root_attr_dist), size=n, p=root_attr_dist)\n",
    "\n",
    "    for child, parents in bn:\n",
    "        child_conditional_distributions = conditional_probabilities[child]\n",
    "        for parents_instance in child_conditional_distributions.keys():\n",
    "            dist = child_conditional_distributions[parents_instance]\n",
    "            parents_instance = list(eval(parents_instance))\n",
    "\n",
    "            # Resolve the error that probabilities do not sum up to 1\n",
    "            dist = np.asarray(dist).astype('float64')\n",
    "            dist = dist / np.sum(dist)\n",
    "\n",
    "            filter_condition = ''\n",
    "            for parent, value in zip(parents, parents_instance):\n",
    "                filter_condition += f\"(synthetic_df['{parent}']=={value})&\"\n",
    "\n",
    "            filter_condition = eval(filter_condition[:-1])\n",
    "            \n",
    "            size = synthetic_df[filter_condition].shape[0]\n",
    "            if size:\n",
    "                synthetic_df.loc[filter_condition, child] = random.choice(len(dist), size=size, p=dist)\n",
    "\n",
    "    synthetic_df[synthetic_df.columns] = synthetic_df[synthetic_df.columns].astype(int)\n",
    "    return synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_vwo = bayesian_network_synthetic_generator(n=len(vwo), bn=bn, conditional_probabilities=conditional_probabilities)\n",
    "synthetic_vwo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb204e1b07e5f73927a864141bea97df8ff49338103976afdc54ba1886ab9c9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
